# app.py

import streamlit as st
from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification
import torch
from PIL import Image
import requests
from bs4 import BeautifulSoup
import docx
import PyPDF2
import pandas as pd
import matplotlib.pyplot as plt
from image_analyzer import analyze_image_sentiment
from sklearn.metrics import classification_report

MODEL_PATH = "models/modernBERT"

@st.cache_resource
def load_model():
    config = AutoConfig.from_pretrained(MODEL_PATH, trust_remote_code=True)
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, config=config, trust_remote_code=True)
    return tokenizer, model, config

tokenizer, model, config = load_model()

def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
        pred_idx = torch.argmax(probs, dim=1).item()
        label = config.id2label[pred_idx]
        confidence = probs[0][pred_idx].item()
    return label, confidence, probs[0]

def predict_sentiments_batch(texts, batch_size=32):
    results = []
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        inputs = tokenizer(batch_texts, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
            pred_ids = torch.argmax(probs, dim=1).tolist()
            labels = [config.id2label[idx] for idx in pred_ids]
        results.extend(labels)
    return results

def extract_text_from_file(file):
    if file.name.endswith(".txt"):
        return file.read().decode("utf-8")
    elif file.name.endswith(".pdf"):
        pdf_reader = PyPDF2.PdfReader(file)
        return "\n".join(page.extract_text() for page in pdf_reader.pages if page.extract_text())
    elif file.name.endswith(".docx"):
        doc = docx.Document(file)
        return "\n".join(paragraph.text for paragraph in doc.paragraphs)
    elif file.name.endswith(".csv"):
        df = pd.read_csv(file)
        return "\n".join(df.astype(str).apply(lambda row: " ".join(row), axis=1).tolist())
    else:
        return ""

def extract_text_from_url(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, "html.parser")
        for tag in soup(["nav", "footer", "aside", "script", "style", "header"]):
            tag.decompose()
        article = soup.find("div", class_="article__text") or soup.find("article") or soup.find("main") or soup.body
        texts = article.stripped_strings
        result = " ".join(texts)
        return result[:3000]
    except Exception as e:
        return f"[–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {e}]"

def plot_sentiment_distribution(probs):
    try:
        labels = list(config.id2label.values())
        values = probs.tolist()

        fig, ax = plt.subplots()
        ax.bar(labels, values, color=['green', 'orange', 'red'][:len(labels)])
        ax.set_ylabel("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å")
        ax.set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
        st.pyplot(fig)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞: {e}")


# –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.markdown("<h1 class='main-title'>–ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞</h1>", unsafe_allow_html=True)
st.markdown("""
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
<style>
    html, body, .stApp {
        background-color: white !important;
        color: #222 !important;
        font-family: 'Inter', 'Segoe UI', 'Roboto', sans-serif;
    }

    .block-container {
        padding: 2rem 2rem 4rem;
        background-color: white !important;
        max-width: 1000px;
        margin: auto;
    }

    header[data-testid="stHeader"],
    [data-testid="stToolbar"] {
        background: white !important;
        visibility: hidden !important;
    }

    /* –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–≤–µ—Ä—Ö—É */
    .main-title {
        text-align: center;
        font-size: 2.2rem;
        font-weight: 700;
        margin-bottom: 2rem;
        color: #111;
    }

    /* –ö–Ω–æ–ø–∫–∏ */
    .stButton button {
        background-color: #f8f9fa !important;
        border: 1px solid #ccc !important;
        border-radius: 10px !important;
        color: #222 !important;
        padding: 0.5rem 1.25rem !important;
        font-weight: 500;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        transition: all 0.2s ease-in-out;
    }

    .stButton button:hover {
        background-color: #e2e6ea !important;
        border-color: #999 !important;
        transform: scale(1.02);
    }

    /* –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è */
    .stTextArea textarea,
    .stTextInput input {
        background-color: #fff !important;
        color: #222 !important;
        border: 1px solid #ccc !important;
        border-radius: 8px !important;
        padding: 0.5rem !important;
        transition: border 0.2s ease-in-out;
    }

    .stTextArea textarea:focus,
    .stTextInput input:focus {
        border-color: #888 !important;
        outline: none !important;
    }

    /* Tabs */
    .stTabs [role="tab"] {
        background-color: #ffffff !important;
        color: #444 !important;
        font-weight: 500;
        border: 1px solid #ddd !important;
        border-radius: 8px 8px 0 0 !important;
        padding: 8px 16px !important;
        margin-right: 4px !important;
    }

    .stTabs [aria-selected="true"] {
        background-color: #f5f5f5 !important;
        color: #000 !important;
        border-bottom: 2px solid black !important;
    }

    /* –ö–æ–¥ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã */
    code, pre, .stCodeBlock {
        background-color: #f5f5f5 !important;
        color: #222 !important;
        border-radius: 6px !important;
        padding: 6px;
        font-size: 14px;
    }

    /* –Ø—Ä–∫–∏–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞ */
    .result-box {
        background-color: #f8f8f8;
        color: #111 !important;
        padding: 1rem 1.5rem;
        border-left: 5px solid #ff4b4b;
        border-radius: 8px;
        font-size: 1.1rem;
        font-weight: 500;
        margin-bottom: 1rem;
    }

    /* –¢–∞–±–ª–∏—Ü—ã */
    .stDataFrame {
        background-color: white !important;
        border: 1px solid #ccc !important;
        border-radius: 6px;
        overflow: hidden;
        box-shadow: 0 2px 6px rgba(0, 0, 0, 0.03);
    }

    h1, h2, h3, h4, h5 {
        color: #111 !important;
        font-weight: 600;
        margin-top: 1.5rem;
        margin-bottom: 0.5rem;
    }

    /* –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }

    ::-webkit-scrollbar-thumb {
        background: #ccc;
        border-radius: 4px;
    }

    ::-webkit-scrollbar-thumb:hover {
        background: #999;
    }

    ::-webkit-scrollbar-track {
        background: #f5f5f5;
    }

    /* –°–ø–∏–Ω–Ω–µ—Ä */
    .stSpinner > div {
        color: black !important;
    }

    /* Drag & Drop */
    [data-testid="stFileDropzone"] {
        background-color: #ffffff !important;
        border: 2px dashed #111 !important;
        color: #111 !important;
        border-radius: 10px !important;
    }
</style>
""", unsafe_allow_html=True)

st.write("–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:")
# –ü–æ–¥–∫–ª—é—á–∞–µ–º —Å—Ç–∏–ª–∏
st.markdown("""<style> /* –í–µ—Å—å CSS, –∫–∞–∫ —É –≤–∞—Å ‚Äî —Ç–æ—Ç –∂–µ */ </style>""", unsafe_allow_html=True)

tab1, tab2, tab3, tab4, tab5 = st.tabs(["üí¨ –¢–µ–∫—Å—Ç", "üìÅ –§–∞–π–ª", "üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "üîó URL", "üìë CSV-—Ç–∞–±–ª–∏—Ü–∞"])

with tab1:
    user_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", height=150)
    if st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç", key="analyze_text"):
        if user_input.strip():
            label, confidence, probs = predict_sentiment(user_input)
            st.markdown(f"""
            <div class="result-box">
                üìä <strong>–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:</strong><br>
                <strong>–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:</strong> {label}<br>
                <strong>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</strong> {confidence * 100:.1f}%
            </div>
            """, unsafe_allow_html=True)
            plot_sentiment_distribution(probs)
        else:
            st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")

with tab2:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª (txt, pdf, docx)", type=["txt", "pdf", "docx"])
    if uploaded_file:
        with st.spinner("üìÇ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞..."):
            raw_text = extract_text_from_file(uploaded_file)  # ‚Üê —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        if raw_text:
            st.subheader("üìÑ –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–∫–∞–∫ –≤ —Ñ–∞–π–ª–µ):")
            st.code(raw_text[:1000] + ("..." if len(raw_text) > 1000 else ""))  # ‚Üê –≤—ã–≤–æ–¥–∏–º –±–µ–∑ –æ—á–∏—Å—Ç–∫–∏

            label, confidence, probs = predict_sentiment(raw_text)  # ‚Üê –∞–Ω–∞–ª–∏–∑ –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É

            st.markdown(f"""
            <div class="result-box">
                üìä <strong>–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:</strong><br>
                <strong>–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:</strong> {label}<br>
                <strong>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</strong> {confidence * 100:.1f}%
            </div>
            """, unsafe_allow_html=True)

            plot_sentiment_distribution(probs)
        else:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞.")

with tab3:
    uploaded_image = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (JPEG/PNG)", type=["jpg", "jpeg", "png"])
    if uploaded_image:
        image = Image.open(uploaded_image)
        st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)
        with st.spinner("üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑..."):
            result = analyze_image_sentiment(image, lambda text: {
                "label": predict_sentiment(text)[0],
                "confidence": predict_sentiment(text)[1]
            })
        st.subheader("üìÑ –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:")
        st.code(result.get("text") or "[–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞]")
        if result.get("confidence") != "N/A":
            st.markdown(f"""
            <div class="result-box">
                üìä <strong>–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:</strong><br>
                <strong>–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:</strong> {result['label']}<br>
                <strong>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</strong> {result['confidence'] * 100:.1f}%
            </div>
            """, unsafe_allow_html=True)
        else:
            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç.")

with tab4:
    url = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç–∞—Ç—å—é/—Å—Ç—Ä–∞–Ω–∏—Ü—É")
    if st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Å—ã–ª–∫—É"):
        if url:
            with st.spinner("üåê –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞..."):
                text = extract_text_from_url(url)
            if text:
                st.subheader("üìÑ –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:")
                st.code(text[:1000] + ("..." if len(text) > 1000 else ""))
                label, confidence, probs = predict_sentiment(text)
                st.markdown(f"""
                <div class="result-box">
                    üìä <strong>–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:</strong><br>
                    <strong>–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:</strong> {label}<br>
                    <strong>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</strong> {confidence * 100:.1f}%
                </div>
                """, unsafe_allow_html=True)
                plot_sentiment_distribution(probs)
            else:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –ø–æ —Å—Å—ã–ª–∫–µ.")

with tab5:
    st.header("üìë –ê–Ω–∞–ª–∏–∑ CSV-—Ç–∞–±–ª–∏—Ü—ã")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'text' –∏ 'label'", type=["csv"])
    if uploaded_file:
        try:
            df = pd.read_csv(uploaded_file, sep=None, engine="python")

            if "text" in df.columns and "label" in df.columns:
                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä—É—Å—Å–∫–∏—Ö –º–µ—Ç–æ–∫ –∫ –∞–Ω–≥–ª. –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è model.config.id2label
                label_map = {
                    "–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π": "negative", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π": "neutral", "–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π": "positive",
                    "negative": "negative", "neutral": "neutral", "positive": "positive"
                }
                df["label"] = df["label"].map(label_map)

                if len(df) > 1000:
                    df = df.head(1000)
                    st.warning("‚ö†Ô∏è CSV —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 1000 —Å—Ç—Ä–æ–∫.")

                st.subheader("üìÑ –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:")
                st.dataframe(df.head())

                with st.spinner("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º..."):
                    texts = df["text"].astype(str).tolist()
                    y_true = df["label"].tolist()
                    y_pred = predict_sentiments_batch(texts)

                    # –í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                    report = classification_report(y_true, y_pred, zero_division=0, output_dict=True)
                    report_df = pd.DataFrame(report).transpose()
                    st.subheader("üìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á—ë—Ç:")
                    st.dataframe(report_df.round(3))

                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
                    st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π:")
                    pred_counts = pd.Series(y_pred).value_counts().reindex(config.id2label.values(), fill_value=0)
                    fig, ax = plt.subplots()
                    pred_counts.plot(kind='bar', color=['green', 'orange', 'red'][:len(pred_counts)], ax=ax)
                    ax.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
                    ax.set_title("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π")
                    st.pyplot(fig)
            else:
                st.error("CSV-—Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'text' –∏ 'label'.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ CSV: {e}")
